# Fast Vision Transformer (ViT) Implementations

Dieses Repository enthÃ¤lt drei verschiedene Implementierungen von Vision Transformern (ViT) fÃ¼r die Bildklassifizierung auf dem CIFAR-10 Datensatz. Jede Implementierung verfolgt einen anderen Ansatz, um die Trainingszeit zu optimieren und die Leistung zu verbessern.

## Ãœberblick der Implementierungen

### 1. FastViT (Basis-Implementierung)
- Verwendet das kleinste ViT-Modell (vit_tiny)
- Implementiert eine zusÃ¤tzliche Feature-Projektionsschicht
- Reduzierter Datensatzumfang fÃ¼r schnelleres Training
- Einfache Datennormalisierung

### 2. FastTransferViT (Transfer Learning)
- Nutzt vortrainiertes ViT-Basismodell
- Implementiert Transfer Learning mit Layer-Freezing
- EnthÃ¤lt Data Augmentation
- Optimierter Klassifizierungskopf

### 3. FastCustomViT (Custom Architecture)
- Trainiert ein angepasstes ViT-Modell ohne Vortraining
- FÃ¼gt eine Faltungsschicht vor dem Embedding hinzu
- Verwendet 20% des CIFAR-10 Datensatzes
- Angepasste Architektur fÃ¼r verbesserte Leistung

## Technische Details

### Gemeinsame Merkmale
- Framework: PyTorch
- Basis-Architektur: Vision Transformer (ViT)
- Datensatz: CIFAR-10 (reduziert)
- Input-GrÃ¶ÃŸe: 224x224 Pixel

### AbhÃ¤ngigkeiten
```python
torch
torchvision
timm
matplotlib
```

### Hardware-Anforderungen
- CUDA-fÃ¤hige GPU (empfohlen)
- Mindestens 8GB RAM
- CPU-Training mÃ¶glich, aber deutlich langsamer

## Installation und Verwendung

1. Repository klonen:
```bash
git clone [repository-url]
```

2. AbhÃ¤ngigkeiten installieren:
```bash
pip install torch torchvision timm matplotlib
```

3. Modell auswÃ¤hlen und trainieren:
```bash
python fast_vit.py        # Basis-Implementierung
python fast_transfer_vit.py    # Transfer Learning
python fast_custom_vit.py      # Custom Architecture
```

## Modellvergleich

### FastViT
- ğŸ”¹ Schnellstes Training
- ğŸ”¹ Geringster Speicherverbrauch
- ğŸ”¸ MÃ¶glicherweise geringere Genauigkeit

### FastTransferViT
- ğŸ”¹ Beste Genauigkeit
- ğŸ”¹ Stabile Konvergenz
- ğŸ”¸ HÃ¶herer Speicherverbrauch

### FastCustomViT
- ğŸ”¹ Gutes Gleichgewicht zwischen Geschwindigkeit und Genauigkeit
- ğŸ”¹ Anpassbare Architektur
- ğŸ”¸ BenÃ¶tigt mehr Feinabstimmung

## Modell-Ausgaben

Jedes Modell speichert:
- Trainierte Gewichte (.pth Datei)
- Trainings-Metriken
- Validierungs-Genauigkeit
